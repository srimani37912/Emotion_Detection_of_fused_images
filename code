# Importing Libraries

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import seaborn as sns
import os

# Importing Deep Learning Libraries

from keras.preprocessing.image import load_img, img_to_array
from keras.preprocessing.image import ImageDataGenerator
from keras.layers import Dense,Input,Dropout,GlobalAveragePooling2D,Flatten,Conv2D,BatchNormalization,Activation,MaxPooling2D
from keras.models import Model,Sequential
from keras.optimizers import Adam,SGD,RMSprop


# Displaying Images

picture_size = 48

folder_path = "/content/drive/MyDrive/images"

expression = 'fear'

plt.figure(figsize= (12,12))
for i in range(1, 10, 1):
    plt.subplot(3,3,i)
    img = load_img(folder_path+"/train/"+expression+"/"+
                  os.listdir(folder_path + "/train/" + expression)[i], target_size=(picture_size, picture_size))
    plt.imshow(img)
plt.show()
  
# Making Training and Validation Data

batch_size  = 128

datagen_train  = ImageDataGenerator()
datagen_val = ImageDataGenerator()

train_set = datagen_train.flow_from_directory(folder_path+"/train",
                                              target_size = (picture_size,picture_size),
                                              color_mode = "grayscale",
                                              batch_size=batch_size,
                                              class_mode='categorical',
                                              shuffle=True)


test_set = datagen_val.flow_from_directory(folder_path+"/validation",
                                              target_size = (picture_size,picture_size),
                                              color_mode = "grayscale",
                                              batch_size=batch_size,
                                              class_mode='categorical',
                                              shuffle=False)

# Model Building
  
from keras.optimizers import Adam,SGD,RMSprop


no_of_classes = 7

model = Sequential()

#1st CNN layer
model.add(Conv2D(64,(3,3),padding = 'same',input_shape = (48,48,1)))
model.add(BatchNormalization())
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size = (2,2)))
model.add(Dropout(0.25))

#2nd CNN layer
model.add(Conv2D(128,(5,5),padding = 'same'))
model.add(BatchNormalization())
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size = (2,2)))
model.add(Dropout (0.25))

#3rd CNN layer
model.add(Conv2D(512,(3,3),padding = 'same'))
model.add(BatchNormalization())
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size = (2,2)))
model.add(Dropout (0.25))

#4th CNN layer
model.add(Conv2D(512,(3,3), padding='same'))
model.add(BatchNormalization())
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Dropout(0.25))

model.add(Flatten())

#Fully connected 1st layer
model.add(Dense(256))
model.add(BatchNormalization())
model.add(Activation('relu'))
model.add(Dropout(0.25))


# Fully connected layer 2nd layer
model.add(Dense(512))
model.add(BatchNormalization())
model.add(Activation('relu'))
model.add(Dropout(0.25))

model.add(Dense(no_of_classes, activation='softmax'))



opt = Adam(lr = 0.0001)
model.compile(optimizer=opt,loss='categorical_crossentropy', metrics=['accuracy'])
model.summary()


# Fitting the Model with Training and Validation Data

  from keras.optimizers import RMSprop,SGD,Adam
from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau

checkpoint = ModelCheckpoint("./model.h5", monitor='val_acc', verbose=1, save_best_only=True, mode='max')

early_stopping = EarlyStopping(monitor='val_loss',
                          min_delta=0,
                          patience=3,
                          verbose=1,
                          restore_best_weights=True
                          )

reduce_learningrate = ReduceLROnPlateau(monitor='val_loss',
                              factor=0.2,
                              patience=3,
                              verbose=1,
                              min_delta=0.0001)

callbacks_list = [early_stopping,checkpoint,reduce_learningrate]

epochs = 48

model.compile(loss='categorical_crossentropy',
              optimizer = Adam(lr=0.001),
              metrics=['accuracy'])

history = model.fit_generator(generator=train_set,
                                steps_per_epoch=train_set.n//train_set.batch_size,
                                epochs=epochs,
                                validation_data = test_set,
                                validation_steps = test_set.n//test_set.batch_size,
                                callbacks=callbacks_list
                                )

# Plotting Accuracy & Loss

plt.style.use('dark_background')

plt.figure(figsize=(20,10))
plt.subplot(1, 2, 1)
plt.suptitle('Optimizer : Adam', fontsize=10)
plt.ylabel('Loss', fontsize=16)
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.legend(loc='upper right')

plt.subplot(1, 2, 2)
plt.ylabel('Accuracy', fontsize=16)
plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.legend(loc='lower right')
plt.show()

# Fusing 
  
import cv2
import os
import numpy as np
import random
import matplotlib.pyplot as plt

from google.colab.patches import cv2_imshow

# Load the video
video_path = '/content/AV.mp4'
cap = cv2.VideoCapture(video_path)

# Create a folder to save frames
frame_folder = '/content/frames'
os.makedirs(frame_folder, exist_ok=True)

# Read frames from the video and save them
frames = []
count = 0
while True:
    ret, frame = cap.read()
    if not ret:
        break
    frame_path = os.path.join(frame_folder, f'frame_{count:04d}.jpg')
    cv2.imwrite(frame_path, frame)
    frames.append(frame_path)
    count += 1

# Randomly select two frames
frame_indices = random.sample(range(len(frames)), 2)
frame1 = cv2.imread(frames[frame_indices[0]])
frame2 = cv2.imread(frames[frame_indices[1]])

# Simple averaging for image fusion
fused_image = cv2.addWeighted(frame1, 0.5, frame2, 0.5, 0)

# Display the original frames
cv2_imshow(frame1)
cv2_imshow(frame2)

# Display the fused image
cv2_imshow(fused_image)
from keras.models import load_model
from keras.preprocessing.image import img_to_array, load_img
import cv2
import numpy as np

face_classifier = cv2.CascadeClassifier(r'/content/haarcascade_frontalface_default.xml')
classifier = load_model(r'/content/model.h5')

emotion_labels = ['Angry', 'Disgust', 'Fear', 'Happy', 'Neutral', 'Sad', 'Surprise']

# Load the image
#image_path = '/content/drive/MyDrive/Frames/fused_image.jpeg'  # Replace with the path to your image
# Load the image directly from the fused_image variable
frame = fused_image
gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)



# Detect faces
faces = face_classifier.detectMultiScale(gray, scaleFactor=1.3, minNeighbors=5)

# If faces are found, analyze the first face detected
if len(faces) > 0:
    (x, y, w, h) = faces[0]
    face_roi = gray[y:y + h, x:x + w]

    # Resize the face to match the input size of the model
    face_roi = cv2.resize(face_roi, (48, 48), interpolation=cv2.INTER_AREA)

    # Convert the face to float and normalize
    face_roi = face_roi.astype('float') / 255.0

    # Expand dimensions and add channel
    face_roi = np.expand_dims(face_roi, axis=0)
    face_roi = np.expand_dims(face_roi, axis=-1)

    # Get probabilities for each emotion
    probabilities = classifier.predict(face_roi)[0]

    # Get the predicted emotion
    predicted_emotion = emotion_labels[np.argmax(probabilities)]

    # Display the emotion label and probabilities
    print(f"Predicted Emotion: {predicted_emotion}")
    for emo, prob in zip(emotion_labels, probabilities):
        print(f"{emo}: {prob:.2f}")

    # Display the emotion label on the image
    cv2.putText(frame, predicted_emotion, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)

else:
    cv2.putText(frame, 'No Faces', (30, 80), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)

# Display the image using matplotlib
plt.imshow(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))
plt.axis('off')
plt.show()
